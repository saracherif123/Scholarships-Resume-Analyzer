{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting text from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 2.5 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Collecting pdfminer.six==20231228\n",
      "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from pdfplumber) (11.1.0)\n",
      "Collecting pypdfium2>=4.18.0\n",
      "  Downloading pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 19.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
      "Collecting cryptography>=36.0.0\n",
      "  Downloading cryptography-44.0.2-cp39-abi3-macosx_10_9_universal2.whl (6.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 65.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from pytesseract) (24.2)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 51.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 38.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pycparser, cffi, cryptography, pypdfium2, pdfminer.six, pytesseract, pdfplumber, pdf2image\n",
      "Successfully installed cffi-1.17.1 cryptography-44.0.2 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.5 pycparser-2.22 pypdfium2-4.30.1 pytesseract-0.3.13\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pdfplumber pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        # Try direct text extraction\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "\n",
    "        if text.strip():\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Direct text extraction failed: {e}\")\n",
    "\n",
    "    # Fallback to OCR for image-based PDFs\n",
    "    print(\"Falling back to OCR for image-based PDF.\")\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        for image in images:\n",
    "            page_text = pytesseract.image_to_string(image)\n",
    "            text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"OCR failed: {e}\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text from PDF:\n",
      "Juan Jose Carin\n",
      "Mountain View, CA 94041\n",
      "650-336-4590 | juanjose.carin@gmail.com\n",
      "Data Scientist\n",
      "linkedin.com/in/juanjosecarin | juanjocarin.github.io\n",
      "Professional Profile\n",
      "Passionate about data analysis and experiments, mainly focused on user behavior, experience, and engagement, with a solid\n",
      "background in data science and statistics, and extensive experience using data insights to drive business growth.\n",
      "Education\n",
      "2016 University of California, Berkeley Master of Information and Data Science GPA: 3.93\n",
      "Relevant courses: • Field Experiments • Data Visualization and\n",
      "• Machine Learning • Applied Regression and Time Series Communication\n",
      "• Machine Learning at Scale Analysis • Research Design and Applications for\n",
      "• Storing and Retrieving Data • Exploring and Analyzing Data Data Analysis\n",
      "2014 Universidad Politécnica de Madrid M.S. in Statistical and Computational Information Processing GPA: 3.69\n",
      "Relevant courses: • Neural Networks and Statistical • Monte Carlo Techniques\n",
      "• Data Mining Learning • Numerical Methods in Finance\n",
      "• Multivariate Analysis • Regression and Prediction Methods • Stochastic Models in Finance\n",
      "• Time Series • Optimization Techniques • Bayesian Networks\n",
      "2005 Universidad Politécnica de Madrid M.S. in Telecommunication Engineering GPA: 3.03\n",
      "Focus Area: Radio communication systems (radar and mobile).\n",
      "Fellowship: First year at University, due to Honors obtained last year at high school.\n",
      "Skills\n",
      "Programming / Statistics Big Data Visualization Others\n",
      "Proficient: R, Python, SQL Hadoop, Hive, MrJob Tableau Git, AWS\n",
      "Intermediate: SPSS, SAS, Matlab Spark, Storm Bash\n",
      "Basic: EViews, Demetra+ D3.js Gephi, Neo4j, QGIS\n",
      "Experience\n",
      "DATA SCIENCE\n",
      "Jan. 2016 – Mar. 2016 Data Scientist\n",
      "CONENTO Madrid, Spain (working remotely)\n",
      "• Designed and implemented the ETL pipeline for a predictive model of traffic on the main roads in\n",
      "eastern Spain (a project for the Spanish government).\n",
      "• Automated scripts in R to extract, transform, clean (incl. anomaly detection), and load into MySQL\n",
      "data from multiple data sources: road traffic sensors, accidents, road works, weather.\n",
      "Jun. 2014 – Sep. 2014 Data Scientist\n",
      "CONENTO Madrid, Spain\n",
      "• Designed an experiment for Google Spain (conducted in October 2014) to measure the impact of\n",
      "YouTube ads on the sales of a car manufacturer's dealer network.\n",
      "• A matched-pair, cluster-randomized design, which involved selecting the test and control groups\n",
      "from a sample of 50+ cities in Spain (where geo-targeted ads were possible) based on their sales-\n",
      "wise similarity over time, using wavelets (and R).\n",
      "MANAGEMENT – SALES (Electrical Eng.)\n",
      "Feb. 2009 – Aug. 2013 Head of Sales, Spain & Portugal – Test &Measurement dept.\n",
      "YOKOGAWA Madrid, Spain\n",
      "• Applied analysis of sales and market trends to decide the direction of the department.\n",
      "• Led a team of 7 people.\n",
      "1 of 2Juan Jose Carin\n",
      "Mountain View, CA 94041\n",
      "650-336-4590 | juanjose.carin@gmail.com\n",
      "Data Scientist\n",
      "linkedin.com/in/juanjosecarin | juanjocarin.github.io\n",
      "• Increased revenue by 6.3%, gross profit by 4.2%, and operating income by 146%, and achieved a 30%\n",
      "ratio of new customers (3x growth), by entering new markets and improving customer service and\n",
      "training.\n",
      "SALES (Electrical Eng. & Telecom.)\n",
      "Apr. 2008 – Jan. 2009 Sales Engineer – Test & Measurement dept.\n",
      "YOKOGAWA Madrid, Spain\n",
      "• Promoted to head of sales after 5 months leading the sales team.\n",
      "Sep. 2004 – Mar. 2008 Sales & Application Engineer\n",
      "AYSCOM Madrid, Spain\n",
      "• Exceeded sales target every year from 2005 to 2007 (achieved 60% of the target in the first 3 months\n",
      "of 2008).\n",
      "EDUCATION\n",
      "Jul. 2002 – Jun. 2004 Tutor of Differential & Integral Calculus, Physics, and Digital Electronic Circuits\n",
      "ACADEMIA UNIVERSITARIA Madrid, Spain\n",
      "• Highest-rated professor in student surveys, in 4 of the 6 terms.\n",
      "• Increased ratio of students passing the course by 25%.\n",
      "Projects\n",
      "See juanjocarin.github.io for additional information\n",
      "2016 SmartCam\n",
      "Capstone Python, OpenCV, TensorFlow, AWS (EC2, S3, DynamoDB)\n",
      "A scalable cloud-based video monitoring system that features motion detection, face counting, and image recognition.\n",
      "2015 Implementation of the Shortest Path and PageRank algorithms with the Wikipedia graph dataset\n",
      "Machine Learning at Scale Hadoop MrJob, Python, AWS EC2, AWS S3\n",
      "Using a graph dataset of almost half a million nodes.\n",
      "2015 Forest cover type prediction\n",
      "Machine Learning Python, Scikit-Learn, Matplotlib\n",
      "A Kaggle competition: predictions of the predominant kind of tree cover, from strictly cartographic variables such as elevation\n",
      "and soil type, using random forests, SVMs, kNNs, Naive Bayes, Gradient Descent, GMMs, …\n",
      "2015 Redefining the job search process\n",
      "Storing and Retrieving Data Hadoop HDFS, Hive, Spark, Python, AWS EC2, Tableau\n",
      "A pipeline that combines data from Indeed API and the U.S. Census Bureau to select the best locations for data scientists\n",
      "based on the number of job postings, housing cost, etc.\n",
      "2015 A fresh perspective on Citi Bike\n",
      "Data Visualization and Communication Tableau, SQLite\n",
      "An interactive website to visualize NYC Citi Bike bicycle sharing service.\n",
      "2015 Investigating the effect of competition on the ability to solve arithmetic problems\n",
      "Field Experiments R\n",
      "A randomized controlled trial in which 300+ participants were assigned to a control group or one of two test groups to\n",
      "evaluate the effect of competition (being compared to no one or someone better or worse).\n",
      "2014 Prediction of customer churn for a mobile network carrier\n",
      "Data Mining SAS\n",
      "Predictions from a sample of 45,000+ customers, using tree decisions, logistic regression, and neural networks.\n",
      "2014 Different models of Harmonized Index of Consumer Prices (HICP) in Spain\n",
      "Time Series SPSS, Demetra+\n",
      "Forecasts based on exponential smoothing, ARIMA, and transfer function (using petrol price as independent variable) models.\n",
      "2 of 2\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"resume_juanjosecarin.pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(\"\\nExtracted Text from PDF:\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Google GenerativeAI Api Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting google.generativeai\n",
      "  Downloading google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
      "\u001b[K     |████████████████████████████████| 175 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[K     |████████████████████████████████| 431 kB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from google.generativeai) (5.29.3)\n",
      "Collecting google-api-core\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-ai-generativelanguage==0.6.15\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 47.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.164.0-py2.py3-none-any.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 36.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from google.generativeai) (4.12.2)\n",
      "Requirement already satisfied: tqdm in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from google.generativeai) (4.67.1)\n",
      "Collecting google-auth>=2.15.0\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "\u001b[K     |████████████████████████████████| 210 kB 32.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting proto-plus<2.0.0dev,>=1.22.3\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from google-api-core->google.generativeai) (2.32.3)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio<2.0dev,>=1.33.2\n",
      "  Downloading grpcio-1.71.0-cp39-cp39-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 20.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio-status<2.0.dev0,>=1.33.2\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from google-auth>=2.15.0->google.generativeai) (5.5.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 29.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2025.1.31)\n",
      "Collecting httplib2<1.dev0,>=0.19.0\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 19.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-httplib2<1.0.0,>=0.2.0\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting uritemplate<5,>=3.0.1\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/sarasaad/Library/Python/3.9/lib/python/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.1)\n",
      "Collecting pydantic-core==2.27.2\n",
      "  Downloading pydantic_core-2.27.2-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 16.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, proto-plus, grpcio, googleapis-common-protos, google-auth, httplib2, grpcio-status, google-api-core, uritemplate, pydantic-core, google-auth-httplib2, annotated-types, pydantic, google-api-python-client, google-ai-generativelanguage, python-dotenv, google.generativeai\n",
      "Successfully installed annotated-types-0.7.0 google-ai-generativelanguage-0.6.15 google-api-core-2.24.2 google-api-python-client-2.164.0 google-auth-2.38.0 google-auth-httplib2-0.2.0 google.generativeai-0.8.4 googleapis-common-protos-1.69.1 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.6 pydantic-core-2.27.2 python-dotenv-1.0.1 rsa-4.9 uritemplate-4.1.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install google.generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"AIzaSyC33fybhJ3mXGQAxYl4ETeIPRC48Pp6GJk\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the capital of Egypt?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"Cairo\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.05822353437542915\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 7,\n",
      "        \"candidates_token_count\": 2,\n",
      "        \"total_token_count\": 9\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cairo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_scholarship_resume(resume_text, scholarship_description=None):\n",
    "    if not resume_text:\n",
    "        return {\"error\": \"Resume text is required for analysis.\"}\n",
    "    \n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    \n",
    "    base_prompt = f\"\"\"\n",
    "    You are an experienced academic advisor specializing in reviewing scholarship applications.\n",
    "    Your task is to evaluate the provided resume and provide feedback regarding the candidate's eligibility, strengths, and areas for improvement for scholarship applications.\n",
    "    \n",
    "    Please assess the following:\n",
    "    - **Academic Qualifications:** Evaluate the candidate’s educational background, GPA, coursework, and any honors or distinctions.\n",
    "    - **Research Experience:** Identify any projects, publications, or research work that support the candidate’s academic standing.\n",
    "    - **Leadership & Extracurricular Activities:** Highlight any leadership roles, volunteer work, or community service.\n",
    "    - **Skills & Personal Growth:** Identify strengths and suggest skills or courses that could improve the candidate’s application.\n",
    "    - **Scholarship Suitability:** Based on the provided information, assess how well the candidate aligns with typical scholarship criteria and suggest ways to strengthen their application.\n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "\n",
    "    if scholarship_description:\n",
    "        base_prompt += f\"\"\"\n",
    "        Additionally, compare this resume to the following scholarship eligibility criteria:\n",
    "        \n",
    "        Scholarship Description:\n",
    "        {scholarship_description}\n",
    "        \n",
    "        Highlight the candidate’s alignment with the criteria, strengths, and areas where they can improve their profile.\n",
    "        \"\"\"\n",
    "\n",
    "    response = model.generate_content(base_prompt)\n",
    "\n",
    "    analysis = response.text.strip()\n",
    "    return analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Resume Evaluation of Juan Jose Carin for a Data Scientist Role\n",
      "\n",
      "**Overall Impression:** Juan Jose Carin presents a strong resume showcasing a diverse background in data science, statistics, and business.  His academic achievements and project portfolio are impressive. However, the resume could benefit from some restructuring and adjustments to better highlight his most relevant skills and experience for a data scientist role.\n",
      "\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Strong Academic Background:**  Two Master's degrees (one in Information and Data Science from UC Berkeley) demonstrate a solid foundation in the field. A high GPA further strengthens this aspect.\n",
      "* **Extensive Technical Skills:**  Proficiency in R, Python, SQL, and experience with various Big Data technologies (Hadoop, Hive, Spark) are highly valuable for a data scientist.  His familiarity with visualization tools (Tableau) is also a plus.\n",
      "* **Demonstrated Project Experience:**  The resume lists numerous projects showcasing practical application of data science techniques, including machine learning, data mining, A/B testing, and data visualization.  The projects are well-described and highlight his accomplishments.\n",
      "* **Significant Experience in Industry:**  His experience at CONENTO and YOKOGAWA demonstrates practical application of his skills in real-world settings.  The quantitative results in his sales management role are impressive and show a results-oriented approach.\n",
      "* **GitHub Portfolio:** The inclusion of a GitHub portfolio is excellent and allows recruiters to assess his coding skills and project quality firsthand.\n",
      "\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "* **Resume Structure and Clarity:** The resume is a bit cluttered and lacks a clear, concise narrative.  The information is presented somewhat chronologically rather than highlighting the most relevant skills and experiences for a data scientist role first.  For instance, the extensive sales experience, while impressive, might overshadow the data science experience in the initial screening phase.\n",
      "* **Lack of Quantifiable Results in Data Science Projects:** While projects are well-described, quantifiable results (e.g., improved model accuracy, reduced error rates, business impact of insights) should be emphasized more prominently for data science projects.  For example, mentioning the accuracy or AUC score of his prediction models would significantly strengthen the impact.\n",
      "* **Skills Section Organization:**  The skills section could be reorganized for better impact. Group skills by category (e.g., Programming Languages, Big Data Technologies, Machine Learning Algorithms, Cloud Platforms, Databases) instead of the current arrangement.  Also, explicitly mention the level of proficiency with specific machine learning algorithms (e.g., Random Forest, SVM, Logistic Regression).\n",
      "* **Outdated Information:** The resume mentions experience from 2014-2016. While this experience is valuable, updating the resume to reflect recent projects and skills is crucial.  Adding new projects or highlighting recent use of mentioned technologies would strengthen the resume significantly.\n",
      "\n",
      "\n",
      "**Skills to Improve:**\n",
      "\n",
      "* **Cloud Computing (Advanced):**  While he mentions AWS, demonstrating advanced skills in cloud platforms (e.g., serverless computing, containerization with Docker and Kubernetes) would be beneficial.\n",
      "* **Data Wrangling and Feature Engineering:**  Highlight experience in advanced data cleaning, transformation, and feature engineering techniques.\n",
      "* **Model Deployment and MLOps:**  Adding skills related to model deployment, monitoring, and maintenance (MLOps) is crucial for many data science roles.\n",
      "* **Specific Machine Learning Algorithms:** Deepen expertise and experience with more advanced machine learning algorithms (e.g., deep learning models, time series forecasting algorithms).\n",
      "* **Communication and Visualization Skills (Advanced):**  While Tableau is mentioned, showcasing advanced data storytelling and communication skills (e.g., creating compelling presentations, communicating complex technical concepts to non-technical audiences) will improve the resume.\n",
      "\n",
      "\n",
      "**Suggested Courses:**\n",
      "\n",
      "* **Cloud Computing (AWS, Azure, or GCP):** Advanced courses on cloud platforms, including serverless architectures, containerization, and deployment pipelines.\n",
      "* **MLOps:** Courses focused on deploying and managing machine learning models in production environments.\n",
      "* **Deep Learning Specialization:**  A deep learning specialization from Coursera, edX, or Udacity would significantly enhance his skillset.\n",
      "* **Advanced Time Series Analysis:** Courses focusing on advanced time series modeling techniques, such as ARIMA, Prophet, etc.\n",
      "* **Data Visualization and Storytelling:**  Courses focusing on creating compelling data visualizations and effectively communicating insights to different audiences.\n",
      "\n",
      "\n",
      "\n",
      "**Alignment with Data Scientist Role:**\n",
      "\n",
      "Juan Jose Carin has a strong profile for a Data Scientist role, especially considering his academic background and project experience.  However, the resume needs improvements to better highlight his most relevant skills and achievements.  Addressing the weaknesses mentioned above, particularly by adding quantifiable results and showcasing advanced skills, will significantly increase his chances of securing a Data Scientist position.  The sales experience, while unrelated to data science at first glance, demonstrates leadership and business acumen which could be a positive asset in the right context.  He should consider tailoring his resume to highlight the transferrable skills from his sales experience, such as analytical thinking, problem-solving, and effective communication.\n"
     ]
    }
   ],
   "source": [
    "print(analyze_resume(resume_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
